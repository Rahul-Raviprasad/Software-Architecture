	1. CAP Theorem: in a distributed system, you can only guarantee two out of the three: Consistency, Availability, and Partition Tolerance.
	2. Consistency: means that every time someone accesses the system, they get the most recent data. 
	3. Availability is about ensuring the system is always up and running, even if some parts of it are having problems.
	4. LDAP: The Lightweight Directory Access Protocol (LDAP) is a directory service protocol that runs directly over the TCP/IP stack. 

https://learn.microsoft.com/en-us/previous-versions/windows/desktop/ldap/lightweight-directory-access-protocol-ldap-api

https://jumpcloud.com/blog/what-is-ldap

	5. Blue Green deployment: In blueâ€“green deployments, two servers are maintained: a "blue" server and a "green" server. At any given time, only one server is handling requests (e.g., being pointed to by the DNS). For example, public requests may be routed to the blue server, making it the production server and the green server the staging server, which can only be accessed on a private network. Changes are installed on the non-live server, which is then tested through the private network to verify the changes work as expected. Once verified, the non-live server is swapped with the live server, effectively making the deployed changes live.
	6. Latency measures the time that data takes to transfer across the network.
	7. Throughput refers to the average volume of data that can actually pass through the network over a specific time. Low-latency systems are essential for real-time applications, whereas high-throughput systems are crucial for data-intensive applications. Example: Online gaming requires low latency to provide real-time interactions among players.A data analytics service prioritizes throughput to process and analyze large datasets over time.
	8. SQL (relational databases) are built on the relational model that organizes data into tables of rows and columns, with a unique key identifying each row. These databases are highly structured and offer powerful query languages, making them ideal for complex queries and transactions. Examples: MySQL, PostgreSQL. However, SQL databases can be challenging to scale horizontally. Example: Banks use SQL databases for transaction management. These databases ensure that all transactions are processed reliably, maintaining accurate account balances and transaction histories.
	9. NoSQL (non-relational databases) offer flexibility and scale easily but might sacrifice SQL like query capabilities and ACID transactions. NoSQL is suited for handling large volumes of unstructured or semi-structured data and for applications requiring quick iterations, and frequent code pushes. Example: Cassandra, Amazon DynamoDB. They come in various types, including document, key-value, wide-column, document and graph stores. Example: Companies like Netflix use NoSQL for real-time recommendation engines. NoSQL databases can quickly process large sets of diverse data (views, ratings, preferences) to deliver personalized content recommendations to millions of users.
	10. Strong vs Eventual Consistency: In the world of distributed systems, where data is stored across multiple locations, ensuring that everyone sees the same data at the same time can be challenging. This is where the concepts of strong and eventual consistency come into play.
	11. Strong consistency means that as soon as a data update occurs, any subsequent access to that data will reflect the update. Example: In a banking system, when you transfer money from one account to another, the system updates the balances immediately.
	12. Eventual consistency, on the other hand, means there might be a delay before an update is visible across all nodes in a system. But, it's guaranteed that if no new updates are made, eventually, all accesses to that data will return the updated value. Example: On a social media platforms like Instagram, when you post a new photo, it might not immediately appear on all your followers' feeds. However, after a short period, everyone will be able to see the latest updates.
	13. Caching is a technique used to speed up access to data by storing a copy of frequently accessed data in a faster storage medium. When it comes to cache strategies, "Read-Through" and "Write-Through" are two common approaches.
	14. read-through cache checks the cache first when data is requested. If the data isn't there (cache miss), it's loaded from the slower primary storage into the cache before being returned. - for read heavy
	15. A write-through cache simultaneously writes data updates to the cache and primary storage, ensuring up-to-date data and reducing data loss risks. - for write heavy
	16. Batch processing involves collecting data over a period of time and then processing it all at once.
	17. Stream processing, on the other hand, deals with data in real-time, processing it as soon as it arrives.
	18. Synchronous processing means tasks are performed one after another. A task must be completed before the next one starts, and the system waits for the outcome before proceeding. 
	19. Asynchronous processing allows tasks to run in the background and doesn't need to wait for it to complete before starting another one. Example: Uploading photos on social media happens asynchronously in the background. You can keep scrolling or exit the app while the photo uploads.
	
